---
title: DynamoDB Capacity
description: Understanding and managing DynamoDB throughput, scaling, and cost optimization
---

DynamoDB capacity determines how much read and write throughput your table can handle. Understanding capacity modes is essential for performance and cost optimization.

## Capacity Modes

<Callout type="info" title="Two Pricing Models">
- **On-Demand**: Pay per request, automatic scaling
- **Provisioned**: Pre-allocated capacity, predictable costs
</Callout>

| Feature | On-Demand | Provisioned |
|---------|-----------|-------------|
| Scaling | Automatic | Manual or Auto Scaling |
| Pricing | Per request | Per hour (capacity units) |
| Minimum | None | 1 RCU, 1 WCU |
| Best for | Variable/unknown traffic | Predictable workloads |
| Reserved capacity | Not available | Up to 77% discount |

## Capacity Units

### Read Capacity Units (RCU)

| Read Type | Calculation |
|-----------|-------------|
| **Strongly consistent** | 1 RCU = 1 read of up to 4 KB |
| **Eventually consistent** | 1 RCU = 2 reads of up to 4 KB |
| **Transactional** | 2 RCUs = 1 read of up to 4 KB |

**Formula:**
```text
RCUs = (Item Size in KB / 4) × Reads per Second × Consistency Factor

Strong: (8 KB / 4) × 100 reads/sec × 1 = 200 RCUs
Eventually: (8 KB / 4) × 100 reads/sec × 0.5 = 100 RCUs
```

### Write Capacity Units (WCU)

| Write Type | Calculation |
|------------|-------------|
| **Standard** | 1 WCU = 1 write of up to 1 KB |
| **Transactional** | 2 WCUs = 1 write of up to 1 KB |

**Formula:**
```text
WCUs = (Item Size in KB) × Writes per Second

Standard: 2 KB × 50 writes/sec = 100 WCUs
Transactional: 2 KB × 50 writes/sec × 2 = 200 WCUs
```

## On-Demand Mode

<Tabs items={['Enable', 'Best Practices']}>
<Tab value="Enable">
```bash title="Create on-demand table"
aws dynamodb create-table \
  --table-name Products \
  --attribute-definitions \
    AttributeName=productId,AttributeType=S \
  --key-schema \
    AttributeName=productId,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST
```

```bash title="Switch to on-demand"
aws dynamodb update-table \
  --table-name Products \
  --billing-mode PAY_PER_REQUEST
```

<Callout type="info">
You can switch between modes once every 24 hours.
</Callout>
</Tab>
<Tab value="Best Practices">
**When to use on-demand:**
- New applications with unknown traffic
- Variable or spiky workloads
- Development and testing environments
- Infrequent, unpredictable access patterns

**Cost considerations:**
- ~5x more expensive per request than provisioned
- No reserved capacity discounts
- Still cost-effective for variable workloads
</Tab>
</Tabs>

## Provisioned Mode

<Tabs items={['Configure', 'Auto Scaling']}>
<Tab value="Configure">
```bash title="Create provisioned table"
aws dynamodb create-table \
  --table-name Products \
  --attribute-definitions \
    AttributeName=productId,AttributeType=S \
  --key-schema \
    AttributeName=productId,KeyType=HASH \
  --billing-mode PROVISIONED \
  --provisioned-throughput \
    ReadCapacityUnits=100,WriteCapacityUnits=50
```

```bash title="Update provisioned capacity"
aws dynamodb update-table \
  --table-name Products \
  --provisioned-throughput \
    ReadCapacityUnits=200,WriteCapacityUnits=100
```
</Tab>
<Tab value="Auto Scaling">
```bash title="Register scalable target"
# Read capacity
aws application-autoscaling register-scalable-target \
  --service-namespace dynamodb \
  --resource-id "table/Products" \
  --scalable-dimension dynamodb:table:ReadCapacityUnits \
  --min-capacity 10 \
  --max-capacity 1000

# Write capacity
aws application-autoscaling register-scalable-target \
  --service-namespace dynamodb \
  --resource-id "table/Products" \
  --scalable-dimension dynamodb:table:WriteCapacityUnits \
  --min-capacity 5 \
  --max-capacity 500
```

```bash title="Create scaling policy"
aws application-autoscaling put-scaling-policy \
  --service-namespace dynamodb \
  --resource-id "table/Products" \
  --scalable-dimension dynamodb:table:ReadCapacityUnits \
  --policy-name ProductsReadScaling \
  --policy-type TargetTrackingScaling \
  --target-tracking-scaling-policy-configuration '{
    "TargetValue": 70.0,
    "PredefinedMetricSpecification": {
      "PredefinedMetricType": "DynamoDBReadCapacityUtilization"
    },
    "ScaleInCooldown": 60,
    "ScaleOutCooldown": 0
  }'
```
</Tab>
</Tabs>

## GSI Capacity

GSIs have separate capacity settings:

```bash title="Update GSI capacity"
aws dynamodb update-table \
  --table-name Products \
  --global-secondary-index-updates '[
    {
      "Update": {
        "IndexName": "CategoryIndex",
        "ProvisionedThroughput": {
          "ReadCapacityUnits": 50,
          "WriteCapacityUnits": 25
        }
      }
    }
  ]'
```

<Callout type="warn">
If a GSI runs out of write capacity, the base table is throttled. Ensure GSI capacity matches write patterns.
</Callout>

## Reserved Capacity

Pre-purchase capacity for significant discounts:

| Term | Discount |
|------|----------|
| 1 year | ~42% off |
| 3 years | ~77% off |

```bash title="Purchase reserved capacity"
# Done through AWS Console or AWS Support
# Cannot be purchased via CLI
```

<Callout type="info">
Reserved capacity is purchased at the region level and applies across all tables.
</Callout>

## Throttling

<Callout type="error" title="What is Throttling?">
When requests exceed provisioned capacity, DynamoDB throttles (rejects) requests. The SDK automatically retries with exponential backoff.
</Callout>

### Detecting Throttles

```bash title="Check throttle metrics"
aws cloudwatch get-metric-statistics \
  --namespace AWS/DynamoDB \
  --metric-name ThrottledRequests \
  --dimensions Name=TableName,Value=Products \
  --start-time $(date -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 \
  --statistics Sum
```

### Avoiding Throttles

<Steps>
<Step>
### Increase Capacity
```bash
aws dynamodb update-table \
  --table-name Products \
  --provisioned-throughput \
    ReadCapacityUnits=500,WriteCapacityUnits=200
```
</Step>
<Step>
### Enable Auto Scaling
Auto scaling reacts to increased load:
```bash
aws application-autoscaling register-scalable-target ...
```
</Step>
<Step>
### Switch to On-Demand
For truly unpredictable workloads:
```bash
aws dynamodb update-table \
  --table-name Products \
  --billing-mode PAY_PER_REQUEST
```
</Step>
<Step>
### Implement Exponential Backoff
The AWS SDK does this automatically. For custom clients:

```javascript title="Exponential backoff"
const executeWithRetry = async (operation, maxRetries = 5) => {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      if (error.name === 'ProvisionedThroughputExceededException') {
        const delay = Math.pow(2, attempt) * 100 + Math.random() * 100;
        await new Promise(r => setTimeout(r, delay));
        continue;
      }
      throw error;
    }
  }
  throw new Error('Max retries exceeded');
};
```
</Step>
</Steps>

## Burst Capacity

<Callout type="info" title="Burst Credits">
DynamoDB accumulates unused capacity for up to 5 minutes, allowing short bursts above provisioned capacity.
</Callout>

| Scenario | Behavior |
|----------|----------|
| Steady traffic below capacity | Burst credits accumulate |
| Traffic spike | Burst credits consumed |
| Credits exhausted | Throttling begins |

**Best practice:** Don't rely on burst capacity for sustained traffic.

## Capacity Calculator

Estimate required capacity:

```javascript title="Capacity calculator"
const calculateCapacity = ({
  itemSizeKB,
  readsPerSecond,
  writesPerSecond,
  consistencyMode = 'eventual', // 'eventual', 'strong', 'transactional'
  writeMode = 'standard' // 'standard', 'transactional'
}) => {
  // RCU calculation
  const itemReadUnits = Math.ceil(itemSizeKB / 4);
  let readMultiplier = 1;
  if (consistencyMode === 'eventual') readMultiplier = 0.5;
  if (consistencyMode === 'transactional') readMultiplier = 2;
  
  const rcuRequired = Math.ceil(itemReadUnits * readsPerSecond * readMultiplier);
  
  // WCU calculation
  const itemWriteUnits = Math.ceil(itemSizeKB);
  const writeMultiplier = writeMode === 'transactional' ? 2 : 1;
  
  const wcuRequired = Math.ceil(itemWriteUnits * writesPerSecond * writeMultiplier);
  
  return { rcuRequired, wcuRequired };
};

// Example
const capacity = calculateCapacity({
  itemSizeKB: 2,
  readsPerSecond: 100,
  writesPerSecond: 50,
  consistencyMode: 'eventual',
  writeMode: 'standard'
});
// { rcuRequired: 50, wcuRequired: 100 }
```

## Hot Partitions

<Callout type="error" title="Hot Partition Problem">
If traffic concentrates on a few partition keys, those partitions can throttle even with available capacity.
</Callout>

### Detecting Hot Partitions

```bash title="Check per-partition metrics"
aws cloudwatch get-metric-statistics \
  --namespace AWS/DynamoDB \
  --metric-name ConsumedReadCapacityUnits \
  --dimensions \
    Name=TableName,Value=Products \
    Name=Operation,Value=GetItem \
  --start-time $(date -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 \
  --statistics Sum
```

### Solutions

<Tabs items={['Write Sharding', 'Caching', 'Better Key Design']}>
<Tab value="Write Sharding">
Distribute writes across multiple partition keys:

```javascript title="Write sharding"
const getShardedKey = (key, shardCount = 10) => {
  const shard = Math.floor(Math.random() * shardCount);
  return `${key}#${shard}`;
};

// Write
await dynamodb.send(new PutCommand({
  TableName: 'HotTable',
  Item: {
    pk: getShardedKey('popular-item'),
    data: 'value'
  }
}));

// Read (query all shards)
const results = await Promise.all(
  Array.from({ length: 10 }, (_, i) =>
    dynamodb.send(new QueryCommand({
      TableName: 'HotTable',
      KeyConditionExpression: 'pk = :pk',
      ExpressionAttributeValues: {
        ':pk': `popular-item#${i}`
      }
    }))
  )
);
```
</Tab>
<Tab value="Caching">
Use DynamoDB Accelerator (DAX) or ElastiCache:

```javascript title="DAX client"
import { DaxClient } from '@amazon-dax/dax-client';

const dax = new DaxClient({
  endpoints: ['my-dax-cluster.dax.us-east-1.amazonaws.com:8111']
});

// Reads hit cache first
const result = await dax.send(new GetCommand({
  TableName: 'Products',
  Key: { productId: 'hot-product' }
}));
```
</Tab>
<Tab value="Better Key Design">
Design partition keys for even distribution:

**Bad:** `status` (few values)
```text
ACTIVE → All active items (hot)
INACTIVE → All inactive items
```

**Good:** `userId` (many values)
```text
user-001 → User's items
user-002 → User's items
...distributed across many partitions
```
</Tab>
</Tabs>

## Adaptive Capacity

<Callout type="info">
DynamoDB automatically redistributes capacity to hot partitions. This handles most hot partition scenarios without intervention.
</Callout>

Adaptive capacity:
- Activates automatically
- Distributes unused capacity to hot partitions
- Up to 3,000 RCUs or 1,000 WCUs per partition

## Monitoring Capacity

### CloudWatch Metrics

```bash title="Get consumed capacity"
aws cloudwatch get-metric-statistics \
  --namespace AWS/DynamoDB \
  --metric-name ConsumedReadCapacityUnits \
  --dimensions Name=TableName,Value=Products \
  --start-time $(date -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date +%Y-%m-%dT%H:%M:%SZ) \
  --period 300 \
  --statistics Sum Average
```

Key metrics:
- **ConsumedReadCapacityUnits/ConsumedWriteCapacityUnits**
- **ProvisionedReadCapacityUnits/ProvisionedWriteCapacityUnits**
- **ReadThrottleEvents/WriteThrottleEvents**
- **ThrottledRequests**

### Set Up Alarms

```bash title="Throttle alarm"
aws cloudwatch put-metric-alarm \
  --alarm-name "DynamoDB-Throttles" \
  --metric-name ThrottledRequests \
  --namespace AWS/DynamoDB \
  --dimensions Name=TableName,Value=Products \
  --statistic Sum \
  --period 60 \
  --threshold 1 \
  --comparison-operator GreaterThanOrEqualToThreshold \
  --evaluation-periods 1 \
  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts
```

## Cost Optimization

<Steps>
<Step>
### Right-Size Capacity
Monitor actual usage and adjust:

```bash title="Check utilization"
aws cloudwatch get-metric-statistics \
  --namespace AWS/DynamoDB \
  --metric-name ConsumedReadCapacityUnits \
  ...
```
</Step>
<Step>
### Use Reserved Capacity
For steady-state workloads, reserve capacity for up to 77% discount.
</Step>
<Step>
### Consider On-Demand
For variable workloads, on-demand may be cheaper despite higher per-request cost.
</Step>
<Step>
### Optimize Item Size
Smaller items = fewer capacity units:

```javascript
// Before: 3 KB item = 3 WCUs
const item = {
  pk: "user-123",
  data: largeJsonObject
};

// After: Compress or store large data in S3
const item = {
  pk: "user-123",
  dataRef: "s3://bucket/key"
};
```
</Step>
<Step>
### Use Eventually Consistent Reads
Half the cost of strongly consistent:

```javascript
await dynamodb.send(new GetCommand({
  TableName: 'Products',
  Key: { productId: 'prod-123' },
  ConsistentRead: false // default
}));
```
</Step>
</Steps>

## Best Practices

<Callout type="info" title="Capacity Best Practices">
1. **Start with on-demand** for new applications
2. **Monitor before provisioning** - understand traffic patterns
3. **Enable auto scaling** for provisioned tables
4. **Set alarms on throttles** - catch issues early
5. **Design for even distribution** - avoid hot partitions
6. **Use DAX for read-heavy workloads** - reduce RCU consumption
7. **Consider reserved capacity** for steady-state production
8. **Optimize item size** - smaller items = lower costs
</Callout>

## Next Steps

<Cards>
  <Card title="Tables" href="/docs/aws/dynamodb/tables" description="Table design" />
  <Card title="Indexes" href="/docs/aws/dynamodb/indexes" description="GSI and LSI" />
  <Card title="Streams" href="/docs/aws/dynamodb/streams" description="Change data capture" />
  <Card title="DynamoDB CLI" href="/docs/aws/dynamodb/cli" description="CLI reference" />
</Cards>
